class Net1D(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(Net1D, self).__init__()
        self.hidden = nn.Linear(input_size, hidden_size)
        self.output = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = torch.tanh(self.hidden(x))
        x = self.output(x)
        return x

class Net2D(nn.Module):
    def __init__(self, input_dimensions, n_hidden_layers, neurons, output_dimensions):
        super().__init__()
        self.input_dimensions = input_dimensions
        self.n_hidden_layers = n_hidden_layers
        self.neurons = neurons
        self.output_dimensions = output_dimensions
        self.activation = nn.Tanh()

        #layers
        self.input_layer = nn.Linear(self.input_dimensions, self.neurons)
        self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers - 1)])
        self.output_layer = nn.Linear(self.neurons, self.output_dimensions)

    def forward(self, x):
        x = self.activation(self.input_layer(x))
        for k, l in enumerate(self.hidden_layers):
            x = self.activation(l(x))
        return self.output_layer(x)
